% CREATED BY DAVID FRISK, 2016
\chapter{Applications}
\label{chapter:application}
As we mentioned in the background section, polynomials have applications to many different areas of study, of which the main three highlighted in the poly-book are dynamical systems, decision systems and databases. Our implemented applications are all instances of the first: we pay no attention to the other two perspectives. Several of our examples are listed in the book and its associated YouTube lecture series, but a few are our own contribution.

It is worth mentioning that many of the ideas in this chapter come from the Categorical Systems Theory book, even though that book does not even mention polynomial functors. What it does do is explain how dynamical systems are modeled by lenses in extreme, welcome detail. It also pays a lot of attention to the distinction between different theories of dynamical systems: stochastic, discrete, continuous etc. This matters to us because several of our examples are continuous systems that are discretized, so strictly speaking we are working within a theory of discrete dynamical systems. David Jaz Myers, the author, is also responsible for the chart-related part of the applications, through his guest lectures on the YouTube series as well as his book.

We will start by talking about the class of systems that \textbf{Poly} mainly talks about - ones that can be expressed through lenses. We'll then explain what our categorical constructs mean in the context of application to dynamical systems, and we'll end by showcasing implemented examples of these dynamical systems, some of which clearly display the advantages of this categorical framework.

\newpage

\section{Mode-dependent open dynamical systems}

First, let's define what a dynamical system is, starting with the simplest case: a closed dynamical system. It can be thought of as a machine with some functionality that "runs" through time. It has a notion of a state space $S$ (in our case a set of values) and a function $f : S \rightarrow S$, called the \textit{dynamics} of the system. The purpose of the dynamics is to reveal what the system's state is at each timestep. Given an initial state $S\_0$, one can then run several steps of a system by simply composing $f$ with itself that many times. This sort of system is called \textit{closed} because it does not take any inputs apart from the initial state, and does not provide any outputs. The only thing one might be interested in is the state of the system. An example of a closed dynamical system is the logistic map, defined by the following equation:
$$
x_{t+1} = rx_t(1 - x_t)
$$
The state space $S$ here is $\mathbb{R}$, and the body of the function $f$ is the expression on the right. The next state is defined in terms of the last state and a parameter $r$, so given an initial state $x_0$, one can generate an infinite sequence of states by running this function repeatedly.
\textit{Open} dynamical systems on the other hand are systems that, in addition to possessing a state space, also provide output to and receive input from their environment. "Environment" here is meant to be interpreted loosely: it is the collection of surrounding systems or user inputs, or some other source of data. Open dynamical systems are then composed of five pieces of data: an input set $A$, an output set $B$, a state space set $S$, and two functions: $\texttt{update} : S \times A \rightarrow S$ and $\texttt{readout} : S \rightarrow B$.  This naturally suggests composition: one systems's output can be another system's input, if the types match.

Finally, \textit{mode-dependent} open dynamical systems are ones in which the sets $A$ and $B$ can vary, and as such, which system is providing output to which other system's input can also change depending on the states of the system. This will become clearer in the next section, where we'll provide visualizations of what is being described here.

\subsection{Wiring diagrams}

Wiring diagrams are a way of expressing morphisms of monoidal categories that is much more visually intuitive and applies to a wide array of contexts, including dynamical systems\cite{operadwd}. In our case, we will use them to express open dynamical systems and their connections.

\begin{tikzpicture}[
    box/.style={rectangle, draw, minimum size=2cm},
    dashedbox/.style={rectangle, draw, dashed},
    every node/.style={midway}
]

% Draw boxes p and q
\node[inner sep=0.5cm] (center) {};
\node[box, above = 0.25cm of center] (p) {$p$};
\node[box, below = 0.25cm of center] (q) {$q$};

% Draw an invisible node around the whole thing
\node[fit margins={left=0.25cm,right=0.5cm,bottom=0.25cm,top=0.25cm},fit=(p) (q)] (outer) {};

% Draw the dashed box using the coordinates of the invisible node
\draw[dashedbox] (outer.south west) rectangle (outer.north east);

% Draw input wire for the dashed box
\draw[-] (outer.west) -- ++(-1,0) node[midway,above] {$A$};

% Draw input wires for p
\draw[-] (p.west) -- (outer.west);

% Draw output wire for p
\draw[-] (p.east) -- ++(0.5,0) node[midway,above] {$B$};
\draw (p.east) -- ++(0.5,0) circle (2pt);

\end{tikzpicture}




An important fact about a system like the one above shows is that they give morphisms in \textbf{Poly}. In this case, this system gives a composition of several arrows, which we will break down exactly how.

\section{Polynomial functors in dynamical systems}

The three main objects of our study - polynomials, lenses and charts - have important roles in the study of dynamical systems, and the categorical structures we've formalized do as well, especially the parallel product $\otimes$. 

\subsection{Polynomials as interfaces}

A polynomial can be seen as the interface or "API" of a dynamical system, by describing what its outputs and inputs are. In particular, the set of positions of a polynomial gives the possible outputs of a system, while the directions at a given position $p$ are the possible inputs given that the state is such that the output from that state is $p$. In this way, the system is mode-dependent. Take the polynomial below for instance.
$$
p(y) = \mathbb{R}y^{\texttt{string}} + \top y^{\mathbb{N} \times \mathbb{N}}
$$
As an interface to an abstract system, it applies to any system that, when its state is such that it outputs real numbers, the possible inputs are strings. When its state is such that it's outputting $\top$ (the singleton set), then the possible inputs to give it are pairs of natural numbers. Notice that this says nothing about what the state space of a system should concretely be, only that its state can specify its interface. Mode-dependence makes it so that writing a polynomial as an abstract box in a wiring diagram is hard, because the input and output wires change. Consider the polynomial above. As boxes, its interface would be both boxes below, depending again on the state:

\todo{draw}

A good way of integrating this mode dependence inherent to polynomials into regular wiring diagrams is an open problem.

\subsection{The parallel product $\otimes$}
We come to a great motivating factor for the naming of this structure: it corresponds to putting systems in parallel. Given two polynomials $p$ and $q$ with their own interfaces, taking their parallel product $p \otimes q$ corresponds to creating a polynomial that has \textit{both interfaces simultaneously}. Intuitively, one can think that any system that has this interface can only run one timestep upon being given both inputs, and it will output both outputs. The structure, in some sense, doesn't "touch" the behavior of the systems at all. In the below picture:

\todo{draw}

The resulting polynomial functor is the dashed line around the two inner boxes, representing $p$ and $q$.

\subsection{Lenses as behaviors}

A particular kind of lens specifies behaviours of systems, namely any lens of shape $f : Sy^S \rightarrow p$, where $p$ is a polynomial like the one described above and $S$ is the state space set. Since lenses are maps on positions and on directions, in this case we get $f : S \rightarrow p(1)$; and $f\# : (\texttt{curState}: S) \rightarrow A (\texttt{f curState}) \rightarrow S$. This corresponds to our definition of open systems, with the added mode dependence: the map on positions is exactly the \texttt{readout} function, and the map on directions is the \texttt{update} function with the added constraint that not any $A$ is valid - $A$ is now a type family, so only the fibrations of $A$ at the position (output) at the current state are valid.

If we draw a behavior-specifying lens on our previous example, not much changes visually, but we denote the state inside the box space as below:

\todo{draw}

This can then be seen as a lens from $S^S \rightarrow p$.

\subsection{Lenses as wiring patterns}

The other role that lenses play in systems of this kind is that they correspond to wiring patterns. For example, consider the abstract drawing of boxes below:

\todo{draw}

This corresponds to a lens from an abstract polynomial placed in the inner box to the abstract polynomial corresponding to the outermost box. We say "abstract" because we need to know nothing about the dynamics or concrete behavior of the systems here, all we need is the types of the interfaces to match. Now there are other wiring patterns possible here:

\todo{drawdrawdraw}

And they all correspond to different lenses. The intuition for the lens structure is that the map on positions selects which of the outer outputs will be served by the inner outputs, and the map on directions will fill in the needed inputs to the inner boxes.

\subsection{Charts as system transformations (??)}

Charts also have a deep interpretation in this context: it turns out that they correspond to \todo{write up charts a bit}. We give an implementation of the example given by David Jaz in his YouTube guest lecture for the polynomial functors course.

\section{Implementing dynamical systems}

Although dynamical systems are "just" lenses of a certain form, we choose a convenient representation for them so as to align with our thinking, analogously to how we choose to represent lenses, charts and polynomials as records and not $\Sigma$-types. A lot of this code is directly translated from the Idris-based implementation in the poly-book's github repository. Our characterization is the following record:
\begin{minted}{agda}
record DynamicalSystem : Set₁ where
    constructor mkdyn
    field
        state : Set -- S
        interface : Polynomial -- p
        dynamics : Lens (selfMonomial state) interface -- Sy^S → p
\end{minted}

When it comes to implementing a framework for coding up dynamical systems in this context, some patterns appear over and over. Some of these patterns are: 
\begin{itemize}
    \item Transforming a pure function $f : A \rightarrow B$ into a memoryless dynamical system, i.e. one that has $A$ as an input, $B$ as output, $A$ as a state space and whose dynamics are given by running the function $f$ on \texttt{readout} and just replace the state with the input in \texttt{update}.

        \begin{minted}{agda}
functionToDynamicalSystem : (A B : Set) → (A → B) → DynamicalSystem
functionToDynamicalSystem A B f = 
  mkdyn B (monomial B A) (id ⇆ (\_ → f))
\end{minted}
    \item Create an \texttt{emitter} polynomial that represents an interface of no inputs (i.e. takes the singleton set) and always outputs the same type.
        \begin{minted}{agda}
emitter : Set → Polynomial
emitter = linear
\end{minted}
    It should not be surprising that this is just the linear polynomial; we give it a special name to bind it to the current interpretation, in the spirit of \textit{concepts with an attitude}\cite{conceptwithattitude}.
    \item Taking the parallel product of two systems. Recall that the parallel product is an operation on objects (polynomials) but it also it is also possible to construct a canonical lens from two lenses $f : A \rightarrow C$ and $g : B \rightarrow D$ of type $\langle f \otimes g \rangle : A \otimes B \rightarrow C \otimes D$. In the context of systems \textit{being} morphisms, this corresponds to putting them "in parallel" and giving rise to a new system, with both state spaces, interfaces and behaviors simultaneously.
    \begin{minted}{agda}
_&&&_ : DynamicalSystem → DynamicalSystem → DynamicalSystem
mkdyn stateA interfaceA dynamicsA &&& mkdyn stateB interfaceB dynamicsB 
    = mkdyn (stateA × stateB)
            (interfaceA ⊗ interfaceB) 
            ⟨ dynamicsA ⊗ dynamicsB ⟩

\end{minted}


    \item Plugging dynamics and wiring patterns together. If lenses account both for dynamics \textit{and} wiring patterns, then it seems natural that a dynamical system (really a lens) that just contains several "free-floating" boxes that are simply sitting in parallel could be composed with a lens that represents a wiring pattern to give rise to a system that is actually usable. Indeed, this is the case, and the function that does this is called \texttt{install} by both us and the poly example code:
    \begin{minted}{agda}
install : (d : DynamicalSystem) → 
          (a : Polynomial) → 
          Lens (DynamicalSystem.interface d) a → 
          DynamicalSystem
install d a l = mkdyn (DynamicalSystem.state d)
                      a 
                      (l ∘ₚ (DynamicalSystem.dynamics d))
\end{minted}
    \item Outer box lens representations. An outer box that represents an enclosure, as well as enclosures of a couple different possible inputs are given: we use \texttt{auto} for most systems, since we're interested in just running them as closed systems and seeing what happens, but sometimes we're interested in giving constant inputs that come from outside the environment, and for that we use \texttt{constI}:
\begin{minted}{agda}
encloseFunction : {t u : Set} → (t → u) → Lens (monomial t u) Y
encloseFunction f = (λ _ → tt) ⇆ (λ fromPos _ → f fromPos)

auto : {m : Set} → enclose (emitter m)
auto = encloseFunction λ _ → tt

constI : {m : Set} → (i : m) → enclose (selfMonomial m)
constI i = encloseFunction λ _ → i
\end{minted}
    One can easily imagining extending \texttt{constI} to taking a function that operates on the number of timesteps so as to vary the input over time as well. This is something that is done in dynamical systems theory in a very informal capacity, under the intuition that the parameters of the system vary "slowly" with respect to the timescale of the state updates. With this framework, we gain the ability of making it precise for free. Of course, if we wanted to make the parameter variation respond to the system's dynamics, we'd need to make it a system in itself; this is a design consideration that we hope future developers take into account.
    \item Finally, there's a function that does what one accustomed to dynamical systems simulations would expect: given an abstract representation of a dynamical system (a value of type \texttt{DynamicalSystem} in our case), and an initial condition, it produces an infinite stream of outputs.
\begin{minted}{agda}
{-# TERMINATING #-}
run : (d : DynamicalSystem) → 
      enclose (DynamicalSystem.interface d) → 
      DynamicalSystem.state d → 
      Stream (Polynomial.position (DynamicalSystem.interface d)) _
run d e initialState =  [ output ] ++ (run d e next)
    where
        output : Polynomial.position (DynamicalSystem.interface d)
        output = Lens.mapPosition (DynamicalSystem.dynamics d) 
                                  initialState
        next : DynamicalSystem.state d
        next = Lens.mapDirection (DynamicalSystem.dynamics d) 
                                 initialState
                                 (Lens.mapDirection e output tt)
\end{minted}
    We need the Agda pragma \texttt{TERMINATING} here because the termination checker can't be sure that this code terminates, since \texttt{run} calls itself on input that is not guaranteed to be smaller.. We can then \texttt{take} on the resulting stream to produce regular Agda lists or vectors, and use them to render plots or print to the screen, and as long as we always run this in the context of a finite \texttt{take} call, the program should always terminate.
\end{itemize}
There are more helpers and utilities peppered throughout the code, but this is the basic glue needed to work with \textbf{Poly} in the context of dynamical systems, as the examples will demonstrate.


\subsection{Examples: Discrete systems}

We split the example implementations in the class of discrete- and continuous-time. As mentioned previously, all examples are in the strict sense discrete; the continuous ones are simply discretized with some $dt$. However, the split is still valid if one considers the spirit of the implementations.

\subsubsection{Fibonacci}
We start with the most basic example of all: a Fibonacci sequence generator implemented as a dynamical system in \textbf{Poly}. The wiring diagram of this system is as follows:
\todo{fibwd}

To break it down: the $+$ function takes two natural numbers and produces one output, and the $id$ function takes a natural number and outputs a natural number. In terms of dynamical systems, however, we have to think about what the \texttt{readout} and \texttt{update} functions are doing for each system: \texttt{readout} can only read what the current state is, and \texttt{update} can only update the state given an input. At every timestep, all systems produce their outputs based on the current state, then all the inputs are read, and the states of all systems are updated. Therefore, the effect of the \texttt{id} function is only felt one timestep later. Hence it plays the subtle role of storing the Fibonacci value computed in the previous timestep, which is why its output is fed as an input to the $+$ function. The code for this system is this:

\begin{minted}[escapeinside=||]{agda}
delay : (A : Set) → DynamicalSystem
delay A = functionToDynamicalSystem A A id

plus : DynamicalSystem
plus = functionToDynamicalSystem (Nat × Nat) Nat (uncurry _+ℕ_)

prefib : DynamicalSystem
prefib = plus &&& delay Nat

fibWiringDiagram : Lens (interface prefib) (emitter Nat)
fibWiringDiagram = (λ {(sumOutput , idOutput) → idOutput})
                    ⇆ 
                    (λ {(sumOutput , idOutput) _ → 
                            (idOutput , sumOutput) , sumOutput })

fibonacci : DynamicalSystem
fibonacci = install prefib (emitter Nat) fibWiringDiagram
\end{minted}

This example provides a good opportunity to understand dynamical systems in the context of polynomials, so let's take the chance to dig in further. In keeping with the previously mentioned intuition, the \texttt{fibWiringDiagram} lens is just one of many possible wiring patterns for an emitter-enclosed system that contains two "floating" dynamical systems that have the interfaces of \texttt{plus} and \texttt{delay Nat}. The outer outputs are the target of the lens, so the polynomial \texttt{emitter Nat}, which is a polynomial that takes the singleton set as input and outputs natural numbers. The inner inputs are given by the wiring pattern in the lens, specifically in the second function (the map on directions). This part of the code:
\begin{minted}{agda}
(λ {(sumOutput , idOutput) _ → 
    (idOutput , sumOutput) , sumOutput })
\end{minted}
is, on the right hand side, saying that the two inputs to \texttt{plus} are given by the output of \texttt{delay Nat} and the its own output, named \texttt{idOutput} and \texttt{sumOutput} respectively in the lambda. The input to \texttt{delay Nat}, on the other hand, is given by the output of the sum: in the next time step, this value will appear in the variable \texttt{idOutput}.

Two final remarks about the Fibonacci sequence generator: the first is that it is actually an efficient way to express Fibonacci dynamics, since there is no recursive calls involved - and the second is that we went into as much detail as possible explaining it so that we can rely on some of the intuition built here to explain the more complicated systems that follow.

\subsubsection{Flip Flop}
Flip Flop is a simple example with two dynamical systems showing how one system can simulate the behavior of another system. This simulation is exactly a special kind of commuting square between charts and lenses. 

Both systems needs to have the same interface, which in this case is a linear polynomial \{on, off\}$y$, that can output either on or off, and always takes unit as input. However, both the state and the behavior of the systems can differ. One of the systems is a flip flop system, with states on or off, with behaviour that outputs this state, and flips the state in the update. The other system has natural numbers as states, outputs the two different states depending on the natural number modulus 2, and updates the state by always taking the successor of the state. Running these systems has the exact same output. This can be expressed concisely by a chart transforming the state space of the natural numbers to either on or off. Then by putting this chart in a commuting square such as shown in diagram \ref{fig:flipFlopSquare}.

\begin{minted}{agda}
data Switch : Set where
    on : Switch
    off : Switch

toggle : Switch → Switch
toggle on = off
toggle off = on

-- | Commonly used where input to enclosed dynamical system where updateState only depends on current state.
ignoreUnitInput : {A B : Set} → (A → B) → A → ⊤ → B
ignoreUnitInput f a tt = f a

-- | Note: linear interface is used to accept only 1 possible input.
--   Readout defined as id to expose state.
flipFlop : DynamicalSystem
flipFlop = mkdyn Switch (linear Switch) (id ⇆ ignoreUnitInput toggle)

-- | Result is: on, off, on, off...
flipFlopRan : Vec Switch 10
flipFlopRan = take 10 $ run flipFlop auto on

modNat : Nat → Switch
modNat n = if n % 2 == 0 then on else off

-- | To compare flipFlop and counter they need to have the same interface.
counter : DynamicalSystem
counter = mkdyn Nat (linear Switch) (modNat ⇆ ignoreUnitInput suc)

-- | Result is: on, off, on, off...
counterRan : Vec Switch 10
counterRan = take 10 $ run counter auto 0

-- | Morphism between p dynamicalSystems with states Nat and Switch.
morphSystem : Nat → Switch
morphSystem = modNat

-- | The square expressing the simulation.
square : LensChartCommute (dynamics counter) (dynamics flipFlop) (morphSystem ⇉ λ _ → morphSystem) idChart
square = law₁ , law₂
\end{minted}

% https://q.uiver.app/?q=WzAsNSxbMCwwLCJOeV4xIl0sWzMsMCwiMnleMSJdLFswLDMsIjJ5XjEiXSxbMywzLCIyeV4xIl0sWzYsMF0sWzAsMiwiXFwlIDIiLDIseyJvZmZzZXQiOjJ9XSxbMiwwLCJzdWMiLDIseyJvZmZzZXQiOjJ9XSxbMSwzLCJpZCIsMix7Im9mZnNldCI6Mn1dLFszLDEsInRvZ2dsZSIsMix7Im9mZnNldCI6Mn1dLFsyLDMsImlkX3tjaGFydH0iLDFdLFswLDEsIlxcJSAyIiwxLHsib2Zmc2V0IjotMn1dLFswLDEsIlxcJTIiLDEseyJvZmZzZXQiOjJ9XV0=
\[\begin{tikzcd}
	{Ny^1} &&& {2y^1} &&& {} \\
	\\
	\\
	{2y^1} &&& {2y^1}
	\arrow["{\% 2}"', shift right=2, from=1-1, to=4-1]
	\arrow["suc"', shift right=2, from=4-1, to=1-1]
	\arrow["id"', shift right=2, from=1-4, to=4-4]
	\arrow["toggle"', shift right=2, from=4-4, to=1-4]
	\arrow["{id_{chart}}"{description}, from=4-1, to=4-4]
	\arrow["{\% 2}"{description}, shift left=2, from=1-1, to=1-4]
	\arrow["{\%2}"{description}, shift right=2, from=1-1, to=1-4]
\end{tikzcd}\]


This showcased how a simple chart in a commuting square can compare behaviour of two different dynamical systems. By generalizing, and using more advanced charts and commuting squares, more advanced comparisons can be made.

\subsubsection{Simulating state machines}
A more advanced example, in comparison to flip flop, is how one state machine can simulate another. This is often expressed as that one state machine is more minimal than another, that is, it has less states but achieves the same behaviour. This is exactly what the special commuting square can express. Because the same idea is followed as for the flip flop example, this example will not be discussed further, but can be found in \textbf{Dynamical/Chart/SimulateStateMachine.agda}.

\subsubsection{Moore machine}
A Moore machine is the same as a lens to a monomial. A Moore machine can be defined as:

\begin{minted}{agda}
record MooreMachine {State Input Output : Set} : Set where
    constructor mkMooreMachine
    field
        readout : State → Output
        update : State → Input → State
\end{minted}

Since a moore machine is a polynomial, it is possible to define the dynamical system as a moore machine and then transport it into a lens, or the other way around.

\subsubsection{Deterministic finite automaton}
A deterministic finite state automaton (DFA) is also a special kind of lens, the lens to the monomial $2y^{alphabet}$. A DFA can be defined as:
\begin{minted}{agda}
record DFS {State Alphabet : Set} : Set where
    constructor mkDFS
    field
        -- Transition function
        update : State → Alphabet → State
        -- Partitions all states into recognized and unrecognized states.
        recognized : State → Bool
\end{minted}

The equality can be defined as a simple isomorphism.

The same trick as for the Moore machine can be used to provide an initial state to the DFA.


\subsubsection{Turing machines}



\subsection{Examples: Continuous systems}
Now we move on to discretized continuous-time systems. They may be treated in much more rigorous mathematical detail than we do here, by representing the state space as topological spaces or manifolds \cite{css}, but as we've mentioned, to showcase their implementation in \textbf{Poly} we discretize them simply according to a differential time $dt$ supplied by the user.
\remarktitle{Supporting Haskell code}
Unfortunately, not all the code in this thesis could be kept in Agda, since it would require too much reimplementation of basic user functionality, or would not be efficient. Therefore, there are the following accompanying tiny Haskell libraries:
\begin{itemize}
    \item A command-line interface library for running the continuous-time systems, since each of them requires different parameters, and using the \texttt{optparse-applicative}\cite{optparse} library.
    \item A plotting library, which renders each system as a collection of values of the system at a sequence of timsteps, written using the \texttt{Chart}\cite{chart-lib} library (not to be confused, of course, with the Chart arrow between polynomials).
    \item A matrix-multiplication library with a single function which takes a list-of-lists representation of a matrix and returns its pseudoinverse. This is needed for the last example. Taking the pseudoinverse of a matrix is a costly operation, and there was an attempt to do it in Agda, but the associated proofs were not trivial and the performance was prohibitively slow. Therefore, we outsource matrix multiplication to the \texttt{hmatrix}\cite{hmatrix} Haskell library, which relies on underlying BLAS \cite{blas} algorithms for speed, while passing \texttt{trustMe} proofs to guarantee matrix sizes at the Agda level.
\end{itemize}
For more information on this supporting code, see the Appendix \ref{app:haskell}.
With this context, we move on the the systems in question.

\subsubsection{Lotka-Volterra}

The Lotka-Volterra predator-prey model is an essential system \cite{Murray2002} that portrays how the population of predators interacts with the population of prey in a given environment. The two main quantities in the model are two real numbers, abstractly representing the amount of the two types of animals - these are its states, in our context. The model is given by the two equations below, where $r$ and $f$ represent our populations of rabbits and foxes - our chosen species of prey and predator:
\begin{equation}
\dot{r} = \alpha r - \beta f r
\label{eq:rabbits}
\end{equation}
\begin{equation}
\dot{f} = \delta f r - \gamma f
\label{eq:foxes}
\end{equation}

The logic of it is that, for rabbits, they will reproduce naturally at a rate $\alpha$, while being hunted at a rate $\beta f$. In other words, their encounters with and subsequent predation by foxes is modeled by multiplying the number of foxes by a "fox appetite" parameter $\beta$. For foxes, their population can be thought of as flourishing or growing at the rate that they can encounter and eat rabbits. This aspect is captured by the term $\delta f r$. They naturally die at a rate of $\gamma$. Note that $\delta$ doesn't have to match $\beta$ - the rate at which foxes eat rabbits is not necessarily the same as the rate at which fox populations grow as a result of being well-fed, though the intuitive relationship between these parameters could be captured by a more sophisticated model.

This system can be represented in terms of our open dynamical systems by considering the rabbit and fox populations as each inhabited by an individual system. They output their population (so \texttt{readout} is the identity function) and that gets fed as an input to the other system, along with any other parameters - in this case $\alpha$, $\beta$, $\delta$ and $\gamma$.

\begin{tikzpicture}[oriented WD, bb min width =.5cm, bbx=.5cm, bb port sep =1,bb port length=0, bby=.15cm, baseline=(Z.center)]
  \node[bb={4}{1}, fill=blue!10] (rabbit) {Rabbits};
  \node[bb={4}{1}, fill=blue!10, below = 8 of rabbit] (fox) {Foxes};

  \node[draw=blue, circle, inner sep = 0] (c2) at ($(fox_out1) + (2, 2)$){$c_2$};
  \node[draw=blue, circle, inner sep = 0, ] (c1) at ($(rabbit_out1-|fox_out1) + (2, -2)$) {$c_1$};

  \node[bb={2}{2}, fit = {($(rabbit.north east) + (5,2)$ ) ($(rabbit.north west) + (-2,0)$) ( $(fox.south east) + (5, -2)$ ) ($(fox.south west) + (-2, 0)$)}] (Z) {};

 \draw (rabbit_out1) to ($(rabbit_out1-|Z_out1) + (0,2)$);
 \draw (rabbit_out1) to[in=170] (c1);
 \draw (rabbit_in1-|Z_in1) to (rabbit_in1);
 \draw (fox_out1) to ($(fox_out1-|Z_out1) + (0,-2)$);
 \draw (fox_out1) to (c2);
 \draw (fox_in4-|Z_in1) to (fox_in4);

 \coordinate[below = 4 of rabbit] (midpoint);
 \draw (c1) to[out=350, in=10, looseness=2] (midpoint);
 \draw (midpoint) to[out=190, in=180, looseness=3] (fox_in1);
 \draw (c2) to[out=10, in=350, looseness=2] (midpoint);
 \draw (midpoint) to[out=170, in=180, looseness=3] (rabbit_in4);
\end{tikzpicture}

Thinking of the systems individually allows us a "separation of concerns" in specifying these systems' behavior that isn't there in environments like Matlab or Python. The code for the rabbit system is:
\begin{minted}[escapeinside=||]{agda}
rabbits : DynamicalSystem
rabbits = mkdyn |$\mathbb{ℝ}$| (mkpoly ℝ λ _ → ℝ × ℝ) (readout ⇆ update)
  where readout : ℝ → ℝ
        readout state = state
        update : ℝ → ℝ × ℝ → ℝ
        update state (birthRabbits , deathRabbits) = 
            state + dt * (state  * (birthRabbits - deathRabbits))
\end{minted}
The differential equation is directly discretized, so the differential amount of time $dt$ goes to the right hand side of \ref{eq:rabbits} and multiplies the entire thing; this is then added to the current state to produce a new state.

Similarly, the fox system is given as:
\begin{minted}{agda}
foxes : DynamicalSystem
foxes = mkdyn ℝ (mkpoly ℝ λ _ → ℝ × ℝ) (readout ⇆ update)
  where readout : ℝ → ℝ
        readout state = state
        update : ℝ → ℝ × ℝ → ℝ
        update state (birthFoxes , deathFoxes) = 
            state + dt * (state * (birthFoxes - deathFoxes))
\end{minted}

Note that each of these systems have only two parameters, whereas by the equations \ref{eq:rabbits} and \ref{eq:foxes}, they ought to have three: \ref{eq:rabbits} should get $\alpha$ and $\beta$ from "outside" the system, whereas \ref{eq:foxes} should get $\delta$ and $\gamma$. It is a somewhat arbitrary choice that we make to make the $\beta$ and $\gamma$ parameters part of the larger system, that is the one given rise to by the composition of these systems tensored with the wiring diagram, and not constants within the system themselves, for instance.

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{figure/lotka_volterra.png}
    \caption{Lotka-Volterra oscillatory dynamics. As the population of rabbits grows, the population of foxes catches up, causing it to go down.}
    \label{fig:lvfig}
\end{figure}

The final system is then a composition with a certain wiring diagram lens:

\begin{minted}{agda}
preLV : DynamicalSystem
preLV = rabbits &&& foxes

-- Wiring diagram is an lens between monomials
lotkaVolterraWiringDiagram : ℝ → ℝ → 
    Lens (DynamicalSystem.interface preLV) (selfMonomial (ℝ × ℝ))
lotkaVolterraWiringDiagram foxPerCapDeath foxHunger = 
  outerOutput ⇆ innerInput
    where outerOutput : ℝ × ℝ → ℝ × ℝ
          outerOutput (rabbitOutput , foxOutput) = 
            rabbitOutput , foxOutput
          innerInput : (outputs : ℝ × ℝ) → 
                       direction (selfMonomial (ℝ × ℝ)) 
                                 (outerOutput outputs) →
                       direction (interface preLV) outputs
          innerInput (r , f) (rabMaxPerCapGrowth , howNutritiousRabbitsAre) = 
            (rabMaxPerCapGrowth , foxHunger * f) , 
            (foxPerCapDeath * r , howNutritiousRabbitsAre)
-- Final system is composition of wiring diagram and dynamics
lotkaVolterra : ℝ → ℝ → DynamicalSystem
lotkaVolterra β γ = install preLV 
                            (selfMonomial (ℝ × ℝ))
                            (lotkaVolterraWiringDiagram β γ)
\end{minted}

Running this system through the command line interface produces the expected oscillating dynamics of the Lotka-Volterra model, albeit with some numerical instability causing the oscillations to grow slightly. Figure \ref{fig:lvfig} shows this dynamics, obtained by running the system through the command line interface with the following parameters.

\begin{minted}{shell}
./Plot LotkaVolterra --alpha 0.2 --beta 0.2 --delta 0.5 \
                     --gamma 0.4 --r0 1.0 --f0 0.9 --dt 0.1
\end{minted}

\todo{make this pretty. perhaps improve the plotting code as well? it's a bit cringe}

\subsubsection{Lorenz system}
The Lorenz system\cite{lorenz1963} is what is known as a chaotic system, in an elementary form. It was introduced by Edward Lorenz as a simplified model of atmospheric convection. The three dimensionless (as in, pure proportions with no physical units) variables $x$, $y$ and $z$ correspond to rate of convection, temperature difference between ascending and descending air currents, and how temperature changes with height. It's given by the following differential equations:

\begin{equation}
\dot{x} = \sigma (y - x)
\label{eq:xlor}
\end{equation}
\begin{equation}
\dot{y} = x(\rho - z) - y
\label{eq:ylor}
\end{equation}
\begin{equation}
\dot{z} = xy - \beta z
\label{eq:zlor}
\end{equation}

The system has three numeric parameters, $\sigma$, $\rho$ and $\beta$ and for specific values of these parameters ($\sigma = 10.0$, $\rho = 28.0$, $\beta = 8/3$), it displays chaotic dynamics - dynamics that have the property of becoming hard to predict as time goes on. What this means is that for two arbitrarily close initial conditions, the distance between the trajectories followed by running the system with these initial conditions grows exponentially, until the trajectories are maximally distant. Figure \ref{fig:lorenzbutterfly} shows an example trajectory of the system with the parameters mentioned above.

\begin{figure}
    \centering
    \includegraphics[width = 0.9\textwidth]{figure/lorenzbutterfly.png}
    \caption{"Lorenz butterfly", a visualization of a trajectory of the Lorenz system. $dt$ is set to 0.01.}
    \label{fig:lorenzbutterfly}
\end{figure}

This is known as a "strange attractor": the system's trajectories eternally oscillate between two attracting states, but it never converges to a single orbit, jumping back and forth. The system is a greatly simplified model of the atmosphere, but provides a good "essence" of chaotic dynamics that are hard to predict, even in just three variables. 

Implementing the Lorenz system in terms of \textbf{Poly} follows the same pattern as the Lotka-Volterra model, by capturing each equation in its own box with its own internal state, with the difference that the external parameters are now fixed, so the inputs are now only the external variables upon which each box should depend. In Agda, the systems are given as:
\begin{minted}{agda}
-- First order differential equations
x : ℝ → DynamicalSystem
x dt = mkdyn X (mkpoly X λ _ → Y) (readout ⇆ update)
  where readout : X → X
        readout state = state
        update : X → Y → X
        update (xnt state) (ynt y) = 
            xnt (state + dt * (σ * (y - state)))

y : ℝ → DynamicalSystem
y dt = mkdyn Y (mkpoly Y λ _ → X × Z) (readout ⇆ update)
  where readout : Y → Y
        readout state = state
        update : Y → X × Z → Y
        update (ynt state) ( xnt x , znt z ) = 
            ynt (state + dt * (x * (ρ - z) - state))

z : ℝ → DynamicalSystem
z dt = mkdyn Z (mkpoly Z λ _ → X × Y) (readout ⇆ update)
  where readout : Z → Z
        readout state = state
        update : Z → X × Y → Z
        update (znt state) (xnt x , ynt y) = 
            znt (state + dt * (x * y - β * state))
\end{minted}
And they're again tensored, producing a system with 3 inputs and 3 outputs, then wired in the right way (x is given as an input to y and z, y to x and z, and z to y, as per the system equations)

\begin{minted}{agda}
preLorenz : ℝ → DynamicalSystem
preLorenz dt = x dt &&& y dt &&& z dt

-- Wiring diagram is an lens between monomials
lorenzWiringDiagram : Lens (interface (preLorenz _))
                           (emitter (X × Y × Z))
lorenzWiringDiagram = mp ⇆ md
  where mp : X × Y × Z → X × Y × Z
        mp (x , y , z) = x , y , z
        md : X × Y × Z → ⊤ → Y × (X × Z) × (X × Y)
        md (x , y , z) _ = y , (x , z) , (x , y)

-- Final system is composition of wiring diagram and dynamics
lorenz : ℝ → DynamicalSystem
lorenz dt = install (preLorenz dt)
                    (emitter (X × Y × Z))
                    lorenzWiringDiagram
\end{minted}

An example run of this system, obtained by \texttt{take} of 1000 timesteps at $dt = 0.01$, is given in Figure \ref{fig:lorenz_dynamics}.

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{figure/lorenz_dynamics.png}
    \caption{Lorenz system chaotic dynamics. The three variables keep oscillating in ever-changing patterns, never settling to a stable cycle.}
    \label{fig:lorenz_dynamics}
\end{figure}


\subsubsection{Hodgkin-Huxley model}
The two examples given in this section are closed systems, meaning they take no input - what this really means is that they take the singleton set as input, so each timestep the element \texttt{tt} is given as a value and the system produces the next output. Now we come to a slightly bigger and more realistic system with 4 equations: the Hodgkin-Huxley \cite{hodgkin1952quantitative} model. It is a system that models action potentials in the giant squid neuron, by thinking of the neuron membranes as circuits, so that the relevant quantities are all electrical (charge, current, capacitance etc). This model captures the flow of sodium and potassium ions through ion channels in the membrane, like in Figure \ref{fig:hodgkinhuxleyschematic}, obtained from \cite{gerstner2014neuronal}.

\begin{figure}
    \centering
    \includegraphics{figure/hodgkinhuxley.png}
    \caption{Analogy schematic of a neuronal membrane modeled as a circuit, from the book Neuronal Dynamics.}
    \label{fig:hodgkinhuxleyschematic}
\end{figure}

The interesting thing about the Hodgkin-Huxley model is that it actually lends itself to being implemented as an open system. There are several equivalent ways of formulating HH as a 4-dimensional dynamical system, but the equations we use are according to this online tutorial \cite{https://mark-kramer.github.io/Case-Studies-Python/HH.html} and given by:

\begin{equation}
\dot{V} =  G_{na}m^3h(E_{na} - V_s) + G_kn^4(E_k - V_s) + G_L * (E_L - V_s) + I_e
\label{eq:voltage}
\end{equation}
\begin{equation}
\dot{m} = \alpha_m(V)(1.0 - m) - \beta_m(V)m
\label{eq:mhh}
\end{equation}
\begin{equation}
\dot{h} = \alpha_h(V)(1.0 - h) - \beta_h(V)h
\label{eq:hhh}
\end{equation}
\begin{equation}
\dot{n} = \alpha_n(V)(1.0 - n) - \beta_n(V)n   
\label{eq:nhh}
\end{equation}

The variables here mean the following: $V$ is the resulting voltage between the intra and extracellular mediums, $m$ encodes potassium channel activation probability, $h$ encodes sodium channel activation probability and $n$ encodes sodium channel \textit{inactivation} probability, and $I_e$ is the driven input voltage. All other symbols are constants and helper functions that have their own deep theoretical justification which we will not get into, we'll just explain the basic logic of the system. The idea is that potassium and sodium channels are positively charged, so their flow across their membrane corresponds to current. However, their flow is not only affected by voltage, but also by concentration: in a chemical setting, substances can saturate a solution regardless of their charge. The interacting probabilities of channels activating (opening, thus allowing particles to flow from more to less concentrated environments) or inactivating give rise to interesting voltage dynamics - the voltage is in fact the output we're interested in for this particular application. Given a strong enough input current, the system can be made to display oscillating behavior, which corresponds to the neuron firing.

The input current can be a constant value, in which case it might as well be treated as a parameter, or an input to an open dynamical system as we've been describing in the framework we work in. This allows us to model "changing a parameter" of a dynamical system, but in a way that is totally internal to our modeling language and does not rely on ad-hoc formulations or programming. For a description of the informal process of analyzing changing a parameter as "turning a knob" at a timescale that is much bigger than the system's dynamics, see this lecture by Shane Ross on the book Nonlinear Dynamics and Chaos by Strogatz: https://www.youtube.com/watch?v=BBd68\_q3Dgg.

The code for the equations themselves, represented as systems, follows the same pattern as the two previous examples. It also involves many fixed constants, discovered experimentally, and so it is quite big, so for the sake of clarity we omit most of it for this system. Instead we focus on the wiring pattern, as well use of \texttt{constI} as a constant input to the system to showcase running a system:
\begin{minted}{agda}
preHH : ℝ → DynamicalSystem
preHH dt = voltage dt &&& 
           potassiumActivation dt &&& 
           sodiumActivation dt &&&
           sodiumInactivation dt

hodgkinHuxleyWiringDiagram : Lens (interface (preHH _)) (selfMonomial ℝ)
hodgkinHuxleyWiringDiagram = 
    (λ {(v , m , h , n) → v }) ⇆ 
    (λ {((v , m , h , n)) Ie → (Ie , m , h , n) , v , v , v })

hodgkinHuxley : ℝ → DynamicalSystem
hodgkinHuxley dt = install (preHH dt)
                           (selfMonomial ℝ)
                           hodgkinHuxleyWiringDiagram

hhSeq : ℝ → Stream ℝ _
hhSeq dt = run (hodgkinHuxley dt) (constI Ie) (V₀ , m∞ , n∞ , h∞)
  where V₀ : ℝ
        V₀ = -70.0
        m∞ : ℝ
        m∞ = 0.05
        n∞ : ℝ
        n∞ = 0.54
        h∞ : ℝ
        h∞ = 0.34
        Ie : ℝ
        Ie = 10.0
\end{minted}

Notice the constant driven input current of 10nA. An example run of the system under this setup, with $dt = 0.02$ and run for 5000 steps, is seen in Figure \ref{fig:hhdynamics}.

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{figure/hodgkin-huxley_dynamics.png}
    \caption{Hodgkin-Huxley model dynamics with input current $I_e = 10$nA and $dt = 0.02$. The simulated neuron fires repeatedly.}
    \label{fig:hhdynamics}
\end{figure}

Since this is a system with input, however, we can exploit this in order to do parameter variation: if we want to see how the system's dynamics vary with a change in parameters that is comparatively slow, we can create a new system whose responsibility is to output the changing current.

Adding this is simple: we take our finished Hodgkin-Huxley system and tensor it with a new system whose only responsibility is to grow its own output at a rate slower than HH's. This "current grower" system is so simple we inline it, using the helper \texttt{functionToDynamicalSystem}. It could have been implemented in other ways - and in fact, this could be its own investigation, like how changing parameters quickly/slowly/exponentially or whatever, could landing systems in different dynamics landscapes. We choose a simple ticking, linear increase at each timestep here.

\begin{minted}{agda}
preHHWithInput : ℝ → DynamicalSystem
preHHWithInput dt = hodgkinHuxley dt &&& 
                    functionToDynamicalSystem ℝ ℝ 
                                              λ x → x + (dt * 0.02)
\end{minted}
We then wire it with HH, taking care to provide the current increaser this time using the \texttt{auto} helper to always give \texttt{tt} as input to the resulting system; we no longer need to provide it an external input of any kind, since this is now built into the system. We also take care with the wiring pattern to give our "current grower" system's output to both itself and to HH. 

\begin{minted}{agda}
hhWithInputWiring : Lens (interface (preHHWithInput 0.0)) (emitter ℝ)
hhWithInputWiring = 
    (λ { (hhOut , _) → hhOut}) ⇆ 
     λ { (hhOut , fnOut) _ → fnOut , fnOut }

hhWithInput : ℝ → DynamicalSystem
hhWithInput dt = install (preHHWithInput dt) (emitter ℝ) hhWithInputWiring

hhSeqWithInput : ℝ → Stream ℝ _
hhSeqWithInput dt = run (hhWithInput dt) auto ((V₀ , m∞ , n∞ , h∞) , -5.0)
  where V₀ : ℝ
        V₀ = -70.0
        m∞ : ℝ
        m∞ = 0.05
        n∞ : ℝ
        n∞ = 0.54
        h∞ : ℝ
        h∞ = 0.34
\end{minted}

The resulting dynamics is what one would expect from Hodgkin-Huxley at the input current levels explored by the current grower, and can be seen in \ref{fig:hhdynamicsinput}.

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{figure/hodgkin-huxley_dynamics-input.png}
    \caption{Hodgkin-Huxley model dynamics with $dt = 0.05$ and input current growing linearly from $-5$nA at a rate of $0.02dt$ per timestep. The simulated neuron starts by not firing, with the resting state slowly growing as the input current grows, then fires repeatedly.}
    \label{fig:hhdynamicsinput}
\end{figure}

\subsubsection{Reservoir computer}
\label{sec:reservoir}
\textit{Reservoir computing} (RC) refers to a broad range of machine learning techniques \cite{reservoiroverview} in the general paradigm of recurrent neural networks. Generally speaking, they involve exploiting the intrisic computations that happen in random, fixed recurrent neural networks (RNNs) to learn how to reproduce complex dynamics i.e. nonlinear timeseries, and have found many applications \cite{windspeedreservoir}\cite{jaeger2002adaptive}. What makes the RC approach attractive is that, since the source of the dynamics is fixed, training is simplified when compared to regular neural networks, which require backpropagation: RCs can be trained by simple linear regression on the output layer. Another advantage is that again, since the dynamics are fixed, they do not need to be implemented in software, and can instead be implemented in physical systems \cite{Cucchi_2022}. Figure \ref{fig:reservoirsetup} contains a schematic showcasing the RC approach compared to neural networks.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figure/reservoir_setup.png}
    \caption{Reservoir setup when compared to neural networks. The dashed box represents an input/output boundary around the reservoir. Figure with modification from Cucchi et al. (2022) \cite{Cucchi_2022}. Licensed under CC BY.}
    \label{fig:reservoirsetup}
\end{figure}

The most representative type of reservoir computer is the \textit{Echo State Network} (ESN) \cite{jaeger2001echo}. In this setup, the reservoir is composed of a large collection of stateful nodes. All nodes are connected to all other nodes, and these connections are weighted. Nodes also carry their own state. The reservoir has an input layer, through which data points of the timeseries to be learned is fed, and an output layer, through which the reservoir's output dynamics are exposed.

To actually use a reservoir to predict a timeseries, the process is organized in three stages, as follows: 

\begin{itemize}
    \item \textbf{Training / data collection}: In this stage, the reservoir accumulates training data from an instance of the nonlinear timeseries it should learn to predict. Both the states and inputs to the system are stored, and this stage ends with the output layer being trained with some form of linear regression.
    \item \textbf{Warm-up / touching}: The reservoir states are reset, and another instance of the nonlinear timeseries (the test data) is provided as input to the reservoir for a limited number of timesteps. This is done so that the system's states have time to reflect an input series and not its own initial values.
    \item \textbf{Prediction / going}: The output of the reservoir is now looped back on itself and given as input. Now it is running essentially as a closed dynamical system, and its outputs should be considered its predictions of how it "thinks" the test timeseries will continue throughout time.
\end{itemize}

The \textit{touch and go} terminology is to invoke an intuition of gradually letting go of some system and letting it run on its own after guiding it for a while. Concretely, we use the following update rule for the reservoir states:

\begin{equation}
res(t + 1) = tanh(W_{res} * res(t) + W_{in}*input)
\label{eq:resupdaterule}
\end{equation}

where $res$ is a vector containing the reservoir states, and the following training method:
\begin{equation}
W_{out} = (H_{states}^T * H_{states} + rI)^{-1} * (H_{states}^T * H_{inputs})
\end{equation}
To explain the variables in order: $H_{states}$ is a matrix representation of the history of states of the reservoir, accumulated in stage 1, and given by \ref{eq:resupdaterule}. $r$ is the ridge parameter, which multiplies the identity matrix $I$. Ridge regression is helpful to avoid overfitting. $H_{inputs}$ is a history of system inputs.

\remarktitle{Reservoir computer in terms of Poly}

We will show an implementation of a reservoir computer that learns the dynamics of the Lorenz system, whose implementation we have already shown. The dashed box in Figure \ref{fig:reservoirsetup} is reminiscent of a polynomial as an interface, and the system taking in inputs from different sources depending on its outputs suggests a mode-dependent dynamical system. Mode-dependence on the type level is not needed, since the systems in question always receive inputs and provide outputs of the same types, but the wiring pattern changes through time. Our situation is with the three wiring patterns below, each corresponding to one of the stages mentioned:

\todo{draw}

Not all of the Agda code is included, since it is quite big and again, readers can consult the implementation in \texttt{Dynamical/Reservoir/ModeDependent.agda}. But some key areas to highlight are the following definitions.

Firstly, the state of the reservoir system:

\begin{minted}{agda}
data ReservoirState (numNodes : ℕ) (systemDim : ℕ) : Set where
  Coll : (nodeStates : Vec ℝ numNodes)
         (counter : ℕ)
         (statesHistory : Vec (Vec ℝ numNodes) counter) 
         (systemHistory : Vec (Vec ℝ systemDim) counter) → 
         ReservoirState numNodes systemDim
  Touch : (nodeStates : Vec ℝ numNodes)
          (counter : ℕ)
          (outputWeights : OutputWeights numNodes systemDim) 
          →
          ReservoirState numNodes systemDim
  Go : (nodeStates : Vec ℝ numNodes)
       (outputWeights : OutputWeights numNodes systemDim)
       →
       ReservoirState numNodes systemDim

\end{minted}
The reservoir ought to start in the \textit{collection} state, where it will accumulate some amount of states AND system history, as well as keep a current set of states for the nodes. It then goes into the \textit{touching} state, where it has a separate counter keeping track of how many state updates to perform before starting prediction. Although the touching state doesn't use the trained output weights obtained from the collection state, it needs to carry it around in order to pass it to the \textit{going} state, where the reservoir is now only concerned with its dynamics.

Second, the output of the reservoir:
\begin{minted}{agda}
data ReservoirOutput (systemDim : ℕ) : Set where
    stillColl : ReservoirOutput systemDim
    stillTouch : ReservoirOutput systemDim
    predicting : Vec ℝ systemDim → ReservoirOutput systemDim
\end{minted}

A regular sum type, since we don't care about what the output of the system is until it's actually ready to predict.

Thirdly, the parallelizing of the systems in question. The interesting thing about this is the \texttt{reservoir} function, which takes some parameters to construct a \texttt{DynamicalSystem}. Here it is made clear that the input and reservoir weights are fixed:

\begin{minted}{agda}
preLorRes : (numNodes trainingSteps touchSteps : ℕ) → 
            (dt : ℝ) → 
            InputWeights numNodes 3 → 
            ReservoirWeights numNodes → 
            DynamicalSystem
preLorRes numNodes trainingSteps touchSteps dt inputWeights reservoirWeights = 
  -- Training system
  lorenz dt &&& 
  -- Test system
  lorenz dt &&&
  -- Reservoir of dynamics + readout layer
  reservoir numNodes 3 trainingSteps touchSteps inputWeights reservoirWeights
\end{minted}

The types \texttt{InputWeights} and \texttt{ReservoirWeights} are just synonyms for matrices. Finally, the wiring pattern lens, which captures the changing inputs depending on system outputs:

\begin{minted}{agda}
lrWiringDiagram : (numNodes trainingSteps touchSteps : ℕ) → 
                  (dt : ℝ) → 
                  (iw : InputWeights numNodes 3) → 
                  (rw : ReservoirWeights numNodes) → 
                  Lens (interface (preLorRes numNodes 
                                             trainingSteps 
                                             touchSteps 
                                             dt 
                                             iw 
                                             rw)) 
                       (emitter (ReservoirOutput 3 × (X × Y × Z)))\
lrWiringDiagram numNodes trainingSteps touchSteps dt iw rw = 
    outerOutputsFrom ⇆ innerInputsFrom
    where outerOutputsFrom : (X × Y × Z) × 
                             (X × Y × Z) × 
                             ReservoirOutput 3 → 
                             ReservoirOutput 3 × (X × Y × Z)
          outerOutputsFrom (_ , test , ro) = ro , test
          -- Provide inputs from different sources
          -- depending on reservoir's output
          innerInputsFrom : (X × Y × Z) × 
                            (X × Y × Z) × 
                            ReservoirOutput 3 → 
                            ⊤ → 
                            (⊤ × ⊤ × Vec ℝ 3)
          innerInputsFrom (lorOut , lorTestOut , stillColl) tt = 
            tt , tt , Lorenz.outToVec lorOut
          innerInputsFrom (lorOut , lorTestOut , stillTouch) tt =
            tt , tt , Lorenz.outToVec lorTestOut
          innerInputsFrom (lorOut , lorTestOut , predicting x) tt = 
            tt , tt , x
\end{minted}

The \texttt{outerOutputsFrom} function just always provides the reservoir output along with the test sequence, so as to facilitate exposing the data to a list we can plot. The \texttt{innerInputsFrom} function, which takes care of filling inputs, is key to representing the three stages: the input to the reservoir is \textit{its own output} when it's started predicting.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figure/reservoir_computer.png}
    \caption{Reservoir dynamics: the reservoir's output along with the test sequence it's trying to predict along all dimensions.}
    \label{fig:reservoir_dynamics}
\end{figure}

For deep mathematical reasons, reservoirs (or any other model of chaotic systems) cannot perfectly reproduce the learned time series. For an in-depth explanation of this, see \cite{strogatz2001nonlinear}. However, they can track the system's dynamics quite well for a while before diverging. Figure \ref{fig:reservoir_dynamics} shows the result of our run over 200 predictions, with 8000 training steps and 600 reservoir nodes - the system, although small, has clearly learned some of the intrinsic properties of the input sequence.